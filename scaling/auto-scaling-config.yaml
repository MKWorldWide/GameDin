# GameDin Quantum Layer Auto-Scaling Configuration
# Comprehensive scaling policies for optimal performance and cost efficiency

---
# Horizontal Pod Autoscaler (HPA) for Quantum Computing Service
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: quantum-computing-hpa
  namespace: gamedin-l3
  labels:
    app: quantum-computing
    component: autoscaling
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: quantum-computing
  minReplicas: 3
  maxReplicas: 20
  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  # Memory-based scaling
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70
  # Custom metrics for quantum task queue
  - type: Object
    object:
      metric:
        name: quantum-task-queue-length
      describedObject:
        apiVersion: v1
        kind: Service
        name: quantum-computing
      target:
        type: AverageValue
        averageValue: 50
  # Custom metrics for response time
  - type: Object
    object:
      metric:
        name: quantum-response-time-p95
      describedObject:
        apiVersion: v1
        kind: Service
        name: quantum-computing
      target:
        type: AverageValue
        averageValue: 2000  # 2 seconds
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min

---
# Vertical Pod Autoscaler (VPA) for resource optimization
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: quantum-computing-vpa
  namespace: gamedin-l3
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: quantum-computing
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: '*'
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2000m
        memory: 4Gi
      controlledValues: RequestsAndLimits

---
# Cluster Autoscaler configuration for EKS
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
  namespace: kube-system
data:
  nodes: |
    {
      "scaleDown": {
        "enabled": true,
        "delayAfterAdd": "10m",
        "delayAfterDelete": "10s",
        "delayAfterFailure": "3m",
        "unneededTime": "10m",
        "utilizationThreshold": 0.5,
        "maxNodeProvisionTime": "15m",
        "scaleDownUnneeded": true,
        "scaleDownUnready": true,
        "maxGracefulTerminationSec": 600
      },
      "scaleUp": {
        "enabled": true,
        "delayAfterAdd": "10s",
        "delayAfterDelete": "10s",
        "delayAfterFailure": "3m",
        "maxNodeProvisionTime": "15m",
        "maxNodeGroups": 4,
        "maxTotalUnreadyPercentage": 45,
        "okTotalUnreadyCount": 3
      }
    }

---
# Node Group Auto Scaling for EKS
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: gamedin-l3-cluster
  region: us-east-1
nodeGroups:
- name: quantum-nodes
  instanceType: c5.2xlarge
  desiredCapacity: 3
  minSize: 2
  maxSize: 10
  volumeSize: 100
  volumeType: gp3
  iam:
    withAddonPolicies:
      autoScaler: true
      ebs: true
      efs: true
  labels:
    node-type: quantum-computing
    environment: production
  tags:
    k8s.io/cluster-autoscaler/node-template/label/node-type: quantum-computing
    k8s.io/cluster-autoscaler/node-template/label/environment: production
  scalingConfig:
    minSize: 2
    maxSize: 10
    desiredSize: 3

---
# Resource Quotas for namespace management
apiVersion: v1
kind: ResourceQuota
metadata:
  name: gamedin-l3-quota
  namespace: gamedin-l3
spec:
  hard:
    requests.cpu: "8"
    requests.memory: 16Gi
    limits.cpu: "16"
    limits.memory: 32Gi
    pods: "20"
    services: "10"
    persistentvolumeclaims: "5"

---
# Priority Class for quantum computing workloads
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: quantum-computing-priority
value: 1000000
globalDefault: false
description: "High priority for quantum computing workloads"

---
# Pod Disruption Budget for high availability
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: quantum-computing-pdb
  namespace: gamedin-l3
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: quantum-computing

---
# Custom Metrics API configuration
apiVersion: v1
kind: Service
metadata:
  name: custom-metrics-api
  namespace: kube-system
  labels:
    app: custom-metrics-api
spec:
  ports:
  - port: 443
    targetPort: 4443
    protocol: TCP
  selector:
    app: custom-metrics-api

---
# Prometheus Adapter for custom metrics
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-adapter
  namespace: kube-system
  labels:
    app: prometheus-adapter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus-adapter
  template:
    metadata:
      labels:
        app: prometheus-adapter
    spec:
      serviceAccountName: prometheus-adapter
      containers:
      - name: prometheus-adapter
        image: k8s.gcr.io/prometheus-adapter/prometheus-adapter:v0.9.1
        args:
        - --cert-dir=/var/run/serving-cert
        - --config=/etc/adapter/config.yaml
        - --logtostderr=true
        - --metrics-relist-interval=1m
        - --prometheus-url=http://prometheus-server.monitoring.svc.cluster.local:9090/
        - --secure-port=4443
        ports:
        - containerPort: 4443
        volumeMounts:
        - name: config
          mountPath: /etc/adapter
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: config
        configMap:
          name: prometheus-adapter-config
      - name: tmp
        emptyDir: {}

---
# Prometheus Adapter Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-adapter-config
  namespace: kube-system
data:
  config.yaml: |
    rules:
    - seriesQuery: 'quantum_task_queue_length{job="quantum-computing"}'
      resources:
        overrides:
          service: {resource: "service"}
          namespace: {resource: "namespace"}
      name:
        matches: "quantum_task_queue_length"
        as: "quantum-task-queue-length"
      metricsQuery: 'quantum_task_queue_length{<<.LabelMatchers>>}'
    
    - seriesQuery: 'quantum_response_time_p95{job="quantum-computing"}'
      resources:
        overrides:
          service: {resource: "service"}
          namespace: {resource: "namespace"}
      name:
        matches: "quantum_response_time_p95"
        as: "quantum-response-time-p95"
      metricsQuery: 'quantum_response_time_p95{<<.LabelMatchers>>}'

---
# Service Account for Prometheus Adapter
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus-adapter
  namespace: kube-system

---
# Cluster Role for Prometheus Adapter
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus-adapter
rules:
- apiGroups: [""]
  resources: ["pods", "services", "nodes"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["custom.metrics.k8s.io"]
  resources: ["*"]
  verbs: ["*"]

---
# Cluster Role Binding for Prometheus Adapter
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus-adapter
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-adapter
subjects:
- kind: ServiceAccount
  name: prometheus-adapter
  namespace: kube-system

---
# APIService for custom metrics
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1beta1.custom.metrics.k8s.io
spec:
  service:
    name: custom-metrics-api
    namespace: kube-system
  group: custom.metrics.k8s.io
  version: v1beta1
  insecureSkipTLSVerify: true
  groupPriorityMinimum: 100
  versionPriority: 100 